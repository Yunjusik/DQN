{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('fastcampus/dataset/cifar/train/*.png')\n",
    "test_paths = glob('fastcampus/dataset/cifar/test/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastcampus/dataset/cifar/train\\\\0_frog.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = train_paths[0]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frog',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'airplane']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'frog', b'automobile', b'ship', b'cat', b'deer', b'airplane',\n",
       "       b'truck', b'dog', b'bird', b'horse'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = tf.unique(train_labels).y.numpy()\n",
    "# 이렇게 해야 중복된 표현들 제대로 제거가 됨.\n",
    "class_names\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'frog'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = tf.strings.split(path, '_')[-1]\n",
    "lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "print(lbl_name.numpy())\n",
    "lbl_name.numpy() == class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name.numpy() == class_names, tf.uint8)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1309, shape=(10,), dtype=uint8, numpy=array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1331, shape=(32, 32, 3), dtype=float32, numpy=\n",
       " array([[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       " \n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       " \n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       " \n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       " \n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1400, shape=(10,), dtype=uint8, numpy=array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_image_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastcampus/dataset/cifar/train\\\\0_frog.png'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1423, shape=(32, 32, 3), dtype=float32, numpy=\n",
       " array([[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       " \n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       " \n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       " \n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       " \n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1492, shape=(10,), dtype=uint8, numpy=array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = load_image_label(path)\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(image), np.max(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preprocessed, label = image_preprocess(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(image)\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_preprocessed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-99b6911969b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_image_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_preprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1145\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3292\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3294\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   2617\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2618\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2619\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 1366\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   1367\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1541\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   1542\u001b[0m         self._function_attributes)\n\u001b[0;32m   1543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    714\u001b[0m                                           converted_func)\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   2611\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   2612\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2613\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2614\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2615\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchO\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   2551\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2553\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2554\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2555\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-6a7a9ccff53d>\u001b[0m in \u001b[0;36mload_image_label\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m  \u001b[1;31m# rescale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-9acb3aa4b08a>\u001b[0m in \u001b[0;36mget_label\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlbl_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0monehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlbl_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0monehot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paths) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1562, 312)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "steps_per_epoch, validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 32, 32, 3]), TensorShape([32, 10]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 14:51:06.893189 17132 nn_ops.py:4283] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0903 14:51:06.913136 17132 nn_ops.py:4283] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0903 14:51:06.933082 17132 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 261s 167ms/step - loss: 1.9059 - accuracy: 0.2777 - val_loss: 1.6387 - val_accuracy: 0.3940\n",
      "Epoch 2/10\n",
      "   1/1562 [..............................] - ETA: 5:31 - loss: 1.6417 - accuracy: 0.3750"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
